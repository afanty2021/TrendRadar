# trendradar/crawler - æ•°æ®é‡‡é›†æ¨¡å—

[æ ¹ç›®å½•](../../CLAUDE.md) > [trendradar](../CLAUDE.md) > **crawler/**

> **æœ€åæ›´æ–°**ï¼š2026-01-31 15:19:33
> **æ¨¡å—ç±»å‹**ï¼šæ•°æ®é‡‡é›†

## æ¨¡å—èŒè´£

æ•°æ®é‡‡é›†æ¨¡å—è´Ÿè´£ä»å¤šä¸ªå¹³å°çˆ¬å–çƒ­æ¦œæ•°æ®å’Œ RSS è®¢é˜…å†…å®¹ã€‚æ”¯æŒ 11 ä¸ªä¸»æµçƒ­æ¦œå¹³å°ï¼ˆä»Šæ—¥å¤´æ¡ã€ç™¾åº¦ã€Bç«™ã€å¾®åšç­‰ï¼‰å’Œæ ‡å‡† RSS/Atom è®¢é˜…æºã€‚

## å…¥å£ä¸å¯åŠ¨

### ä¸»è¦å…¥å£
- **`fetcher.py`**ï¼šçƒ­æ¦œæ•°æ®çˆ¬è™«
- **`rss/fetcher.py`**ï¼šRSS è®¢é˜…çˆ¬è™«
- **`rss/parser.py`**ï¼šRSS è§£æå™¨

### ä½¿ç”¨æ–¹å¼
```python
from trendradar.crawler.fetcher import DataFetcher
from trendradar.crawler.rss.fetcher import RSSFetcher

# çƒ­æ¦œçˆ¬å–
fetcher = DataFetcher(config)
news_data = await fetcher.crawl_websites()

# RSS çˆ¬å–
rss_fetcher = RSSFetcher(config)
rss_data = await rss_fetcher.fetch_all_rss()
```

## å¯¹å¤–æ¥å£

### DataFetcher ç±»

**fetcher.py**
```python
class DataFetcher:
    """çƒ­æ¦œæ•°æ®çˆ¬è™«"""

    async def crawl_websites(
        self,
        platforms: Optional[List[str]] = None
    ) -> NewsData:
        """çˆ¬å–æ‰€æœ‰å¹³å°çƒ­æ¦œ"""

    async def fetch_single_platform(
        self,
        platform_id: str,
        platform_config: Dict
    ) -> Optional[Dict]:
        """çˆ¬å–å•ä¸ªå¹³å°"""

    def get_request_interval(
        self,
        base_interval: float
    ) -> float:
        """è·å–å¸¦æŠ–åŠ¨çš„è¯·æ±‚é—´éš”"""
```

### RSSFetcher ç±»

**rss/fetcher.py**
```python
class RSSFetcher:
    """RSS è®¢é˜…çˆ¬è™«"""

    async def fetch_all_rss(
        self,
        feed_ids: Optional[List[str]] = None
    ) -> RSSData:
        """è·å–æ‰€æœ‰ RSS æº"""

    async def fetch_single_feed(
        self,
        feed_id: str,
        feed_config: Dict
    ) -> Optional[RSSFeed]:
        """è·å–å•ä¸ª RSS æº"""

    def filter_fresh_articles(
        self,
        articles: List[Dict],
        max_age_days: int
    ) -> List[Dict]:
        """è¿‡æ»¤æ–°é²œæ–‡ç« """
```

### è§£æå‡½æ•°

**rss/parser.py**
```python
def parse_rss_content(
    raw_content: str,
    feed_id: str
) -> Optional[RSSFeed]:
    """è§£æ RSS/Atom å†…å®¹"""

def extract_publish_time(
    entry: Dict,
    feed_id: str
) -> Optional[datetime]:
    """æå–å‘å¸ƒæ—¶é—´"""
```

## å…³é”®ä¾èµ–ä¸é…ç½®

### å†…éƒ¨ä¾èµ–
```
trendradar/
â””â”€â”€ crawler/
    â”œâ”€â”€ fetcher.py       # çƒ­æ¦œçˆ¬è™«
    â””â”€â”€ rss/
        â”œâ”€â”€ fetcher.py   # RSS çˆ¬è™«
        â””â”€â”€ parser.py    # RSS è§£æ
```

### å¤–éƒ¨ä¾èµ–
- **requests**ï¼šHTTP è¯·æ±‚
- **feedparser**ï¼šRSS è§£æ

### æ”¯æŒçš„å¹³å°

| å¹³å° ID | å¹³å°åç§° | API ç«¯ç‚¹ |
|---------|---------|---------|
| toutiao | ä»Šæ—¥å¤´æ¡ | NewsNow API |
| baidu | ç™¾åº¦ | NewsNow API |
| bilibili | Bç«™ | NewsNow API |
| weibo | å¾®åš | NewsNow API |
| zhihu | çŸ¥ä¹ | NewsNow API |
| wallstreetcn | åå°”è¡—è§é—» | NewsNow API |
| thepaper | æ¾æ¹ƒæ–°é—» | NewsNow API |
| cls | è´¢è”ç¤¾ | NewsNow API |
| ifeng | å‡¤å‡°ç½‘ | NewsNow API |
| tieba | è´´å§ | NewsNow API |
| douyin | æŠ–éŸ³ | NewsNow API |

### é…ç½®ç¤ºä¾‹
```yaml
crawler:
  request_interval: 1.0      # åŸºç¡€è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
  jitter_range: 0.5          # éšæœºæŠ–åŠ¨èŒƒå›´
  timeout: 10                # è¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰
  retry_times: 3             # é‡è¯•æ¬¡æ•°
  proxy:                     # ä»£ç†é…ç½®
    enabled: false
    http_proxy: ""
    https_proxy: ""

rss:
  freshness_filter:
    enabled: true
    max_age_days: 3
```

## æ•°æ®æ¨¡å‹

### NewsData
```python
@dataclass
class NewsData:
    crawl_date: str                # çˆ¬å–æ—¥æœŸ
    crawl_time: str                # çˆ¬å–æ—¶é—´
    results: Dict                  # å¹³å°æ•°æ®
    id_to_name: Dict               # å¹³å°åç§°æ˜ å°„
    failed_ids: List               # å¤±è´¥å¹³å°åˆ—è¡¨
```

### RSSData
```python
@dataclass
class RSSData:
    date: str                      # æ—¥æœŸ
    feeds: Dict                     # RSS æºæ•°æ®
    id_to_name: Dict                # æºåç§°æ˜ å°„
```

### RSSFeed
```python
@dataclass
class RSSFeed:
    feed_id: str                   # æº ID
    feed_url: str                  # æº URL
    title: str                     # æºæ ‡é¢˜
    articles: List[Dict]           # æ–‡ç« åˆ—è¡¨
```

## æµ‹è¯•ä¸è´¨é‡

**å½“å‰çŠ¶æ€**ï¼šæœªé…ç½®æµ‹è¯•

**å»ºè®®æµ‹è¯•è¦†ç›–**ï¼š
- `DataFetcher.crawl_websites()`ï¼šçˆ¬å–æµç¨‹æµ‹è¯•
- `RSSFetcher.fetch_all_rss()`ï¼šRSS è·å–æµ‹è¯•
- è§£æå™¨æµ‹è¯•
- é‡è¯•æœºåˆ¶æµ‹è¯•

## å¸¸è§é—®é¢˜ (FAQ)

### Q1: å¦‚ä½•æ·»åŠ æ–°å¹³å°ï¼Ÿ

**A**: åœ¨ `config.yaml` æ·»åŠ å¹³å°é…ç½®ï¼Œç¡®ä¿ NewsNow API æ”¯æŒè¯¥å¹³å°ã€‚

### Q2: å¦‚ä½•è°ƒæ•´è¯·æ±‚é€Ÿåº¦ï¼Ÿ

**A**: ä¿®æ”¹é…ç½®ï¼š
```yaml
crawler:
  request_interval: 2.0    # å¢åŠ é—´éš”
  jitter_range: 1.0        # å¢åŠ æŠ–åŠ¨
```

### Q3: å¦‚ä½•ä½¿ç”¨ä»£ç†ï¼Ÿ

**A**: é…ç½®ä»£ç†ï¼š
```yaml
crawler:
  proxy:
    enabled: true
    http_proxy: "http://127.0.0.1:7890"
    https_proxy: "http://127.0.0.1:7890"
```

### Q4: RSS æ–‡ç« é‡å¤æ¨é€ï¼Ÿ

**A**: å¯ç”¨æ–°é²œåº¦è¿‡æ»¤ï¼š
```yaml
rss:
  freshness_filter:
    enabled: true
    max_age_days: 3
```

## ç›¸å…³æ–‡ä»¶æ¸…å•

- `fetcher.py`ï¼šçƒ­æ¦œçˆ¬è™«ï¼Œçº¦ 152 è¡Œ
- `rss/fetcher.py`ï¼šRSS çˆ¬è™«ï¼Œçº¦ 156 è¡Œ
- `rss/parser.py`ï¼šRSS è§£æå™¨ï¼Œçº¦ 130 è¡Œ

## å˜æ›´è®°å½• (Changelog)

### 2026-01-31 15:19:33
- âœ¨ åˆ›å»ºæ¨¡å—æ–‡æ¡£
- ğŸ“Š å®Œæˆæ¥å£ä¸é…ç½®åˆ†æ

---

*æœ¬æ–‡æ¡£ç”± AI è‡ªåŠ¨ç”Ÿæˆå¹¶ç»´æŠ¤*
